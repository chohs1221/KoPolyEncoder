============================================================
File Name: poly220923_0506_bs256_ep5_data1363581
START!! 2022_09_23 / 05_06
model: poly
path: skt/kobert-base-v1
trainset: train_1363581
validset: valid_170448
m: 360
seed: 42
epoch: 5
learning rate: 5e-05
batch size: 256
accumulation: 1
description: 

train: 1363581
valid: 170448
['유튜브에서 봤는데 토너로 피부 닦는 거 하지 말라더라.', '나도 각질을 닦아준다고 들었었는데 잘못된 정보였나 봐.', '응. 닦아내는 게 자극적이라서 피부가 예민해진대.', '약하게 한다고 해도 닦다 보면 저절로 힘이 들어가잖아.', '그리고 손으로 바르는게 피부에 흡수도 더 잘 되는 느낌이야.']
['정말? 나 항상 그렇게 쓰고 있는데!', '그럼 그냥 손으로 바르는 게 좋다는 말이지?', '어쩐지 요즘 피부가 좀 거칠어지는 느낌이 들긴 했어.', '지금부터 손으로 발라야겠다.', '엄청 오래전에 얼굴에 손이 닿지 않게 거품으로만 세안하는 방법이 유행이었는데']

train loss: 3.479993228625534 -------------------- epoch: 0 iteration: 532
valid loss: 4.479344100207538 -------------------- epoch: 0 iteration: 532
save best model - epoch: 0, loss: 4.479344100207538
train loss: 2.1102607324159237 -------------------- epoch: 0 iteration: 1064
valid loss: 6.052535364219734 -------------------- epoch: 0 iteration: 1064
train loss: 1.4968564864388085 -------------------- epoch: 0 iteration: 1596
valid loss: 6.398802629820219 -------------------- epoch: 0 iteration: 1596
train loss: 1.3381312760643493 -------------------- epoch: 0 iteration: 2128
valid loss: 6.125698122534308 -------------------- epoch: 0 iteration: 2128
train loss: 1.2578999438232048 -------------------- epoch: 0 iteration: 2660
valid loss: 5.7437090787801655 -------------------- epoch: 0 iteration: 2660
train loss: 1.210125063595019 -------------------- epoch: 0 iteration: 3192
valid loss: 7.412399753077968 -------------------- epoch: 0 iteration: 3192
train loss: 1.1938285438862062 -------------------- epoch: 0 iteration: 3724
valid loss: 6.428251918729719 -------------------- epoch: 0 iteration: 3724
train loss: 1.1803462009008665 -------------------- epoch: 0 iteration: 4256
valid loss: 7.075036982516269 -------------------- epoch: 0 iteration: 4256
train loss: 1.1581693129207855 -------------------- epoch: 0 iteration: 4788
valid loss: 6.133929056448263 -------------------- epoch: 0 iteration: 4788
train loss: 1.1306376756357968 -------------------- epoch: 0 iteration: 5320
valid loss: 7.125344852069476 -------------------- epoch: 0 iteration: 5320
train loss: 1.1871014020048587 -------------------- epoch: 1 iteration: 532
valid loss: 6.7750721486123116 -------------------- epoch: 1 iteration: 532
train loss: 1.129432426023304 -------------------- epoch: 1 iteration: 1064
valid loss: 12.395394906625375 -------------------- epoch: 1 iteration: 1064
train loss: 1.4562753877021317 -------------------- epoch: 1 iteration: 1596
valid loss: 21.987109026751362 -------------------- epoch: 1 iteration: 1596
train loss: 1.4120900902084839 -------------------- epoch: 1 iteration: 2128
valid loss: 12.452712610319212 -------------------- epoch: 1 iteration: 2128
train loss: 1.3564534580573104 -------------------- epoch: 1 iteration: 2660
valid loss: 11.426900969611275 -------------------- epoch: 1 iteration: 2660
train loss: 1.714227837279327 -------------------- epoch: 1 iteration: 3192
valid loss: 5.570964345702896 -------------------- epoch: 1 iteration: 3192
train loss: 2.1672053892809644 -------------------- epoch: 1 iteration: 3724
valid loss: 6.0604204608871415 -------------------- epoch: 1 iteration: 3724
train loss: 2.0767371865143454 -------------------- epoch: 1 iteration: 4256
valid loss: 5.531152579877469 -------------------- epoch: 1 iteration: 4256
train loss: 2.009225499585159 -------------------- epoch: 1 iteration: 4788
valid loss: 6.34123186950569 -------------------- epoch: 1 iteration: 4788
train loss: 1.9913634315021056 -------------------- epoch: 1 iteration: 5320
valid loss: 6.607683470299294 -------------------- epoch: 1 iteration: 5320
train loss: 1.9030463543153346 -------------------- epoch: 2 iteration: 532
valid loss: 5.67389989328814 -------------------- epoch: 2 iteration: 532
train loss: 1.8180625181000931 -------------------- epoch: 2 iteration: 1064
valid loss: 5.422982138556403 -------------------- epoch: 2 iteration: 1064
train loss: 1.8969568424206926 -------------------- epoch: 2 iteration: 1596
valid loss: 6.054943478501237 -------------------- epoch: 2 iteration: 1596
train loss: 1.7762256717323361 -------------------- epoch: 2 iteration: 2128
valid loss: 5.580723263479926 -------------------- epoch: 2 iteration: 2128
train loss: 1.7330031910337003 -------------------- epoch: 2 iteration: 2660
valid loss: 6.7081776044748205 -------------------- epoch: 2 iteration: 2660
train loss: 1.6456292934883805 -------------------- epoch: 2 iteration: 3192
valid loss: 6.159730329169883 -------------------- epoch: 2 iteration: 3192
train loss: 1.6039230435862577 -------------------- epoch: 2 iteration: 3724
valid loss: 5.4852380058070915 -------------------- epoch: 2 iteration: 3724
train loss: 1.5947732945582025 -------------------- epoch: 2 iteration: 4256
valid loss: 5.7215729540174785 -------------------- epoch: 2 iteration: 4256
train loss: 1.5608629691869693 -------------------- epoch: 2 iteration: 4788
valid loss: 8.030459667469287 -------------------- epoch: 2 iteration: 4788
train loss: 1.5615116794754689 -------------------- epoch: 2 iteration: 5320
valid loss: 8.825075017081367 -------------------- epoch: 2 iteration: 5320
train loss: 1.5314019156577892 -------------------- epoch: 3 iteration: 532
valid loss: 5.059156832394299 -------------------- epoch: 3 iteration: 532
train loss: 1.4799949544713014 -------------------- epoch: 3 iteration: 1064
valid loss: 6.4304957712018815 -------------------- epoch: 3 iteration: 1064
train loss: 1.4823787382670812 -------------------- epoch: 3 iteration: 1596
valid loss: 5.988343206611839 -------------------- epoch: 3 iteration: 1596
train loss: 1.4673141678024952 -------------------- epoch: 3 iteration: 2128
valid loss: 9.227208438936296 -------------------- epoch: 3 iteration: 2128
train loss: 1.4738293191544096 -------------------- epoch: 3 iteration: 2660
valid loss: 6.063909821324162 -------------------- epoch: 3 iteration: 2660
train loss: 1.4043729195469303 -------------------- epoch: 3 iteration: 3192
valid loss: 5.249327916640777 -------------------- epoch: 3 iteration: 3192
train loss: 1.414876896860008 -------------------- epoch: 3 iteration: 3724
valid loss: 6.998642708804156 -------------------- epoch: 3 iteration: 3724
train loss: 1.4022394510588252 -------------------- epoch: 3 iteration: 4256
valid loss: 5.38512205361604 -------------------- epoch: 3 iteration: 4256
train loss: 1.5033384978323054 -------------------- epoch: 3 iteration: 4788
valid loss: 6.133213523629907 -------------------- epoch: 3 iteration: 4788
train loss: 1.4211697361074893 -------------------- epoch: 3 iteration: 5320
valid loss: 5.525673315689729 -------------------- epoch: 3 iteration: 5320
train loss: 1.395946374401114 -------------------- epoch: 4 iteration: 532
valid loss: 5.632460047890832 -------------------- epoch: 4 iteration: 532
train loss: 1.3704140159420501 -------------------- epoch: 4 iteration: 1064
valid loss: 6.1599748191890775 -------------------- epoch: 4 iteration: 1064
train loss: 1.3931694380322794 -------------------- epoch: 4 iteration: 1596
valid loss: 6.585248217568383 -------------------- epoch: 4 iteration: 1596
train loss: 1.3855301903602772 -------------------- epoch: 4 iteration: 2128
valid loss: 5.290645129687793 -------------------- epoch: 4 iteration: 2128
train loss: 1.3983231460241448 -------------------- epoch: 4 iteration: 2660
valid loss: 9.517127650636095 -------------------- epoch: 4 iteration: 2660
train loss: 1.4127257822599626 -------------------- epoch: 4 iteration: 3192
valid loss: 6.245608234548712 -------------------- epoch: 4 iteration: 3192
train loss: 1.3761446558891381 -------------------- epoch: 4 iteration: 3724
valid loss: 5.92222219544488 -------------------- epoch: 4 iteration: 3724
train loss: 1.3703156158440095 -------------------- epoch: 4 iteration: 4256
valid loss: 8.337960735813633 -------------------- epoch: 4 iteration: 4256
train loss: 1.4161502943003088 -------------------- epoch: 4 iteration: 4788
valid loss: 5.854280084461063 -------------------- epoch: 4 iteration: 4788
train loss: 1.4155049431592899 -------------------- epoch: 4 iteration: 5320
valid loss: 8.97886375478796 -------------------- epoch: 4 iteration: 5320
END!! 2022_09_23 / 15_21
RUNNING TIME: 10:14:2
============================================================



