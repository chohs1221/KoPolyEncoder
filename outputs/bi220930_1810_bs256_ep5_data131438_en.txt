============================================================
File Name: bi220930_1810_bs256_ep5_data131438_en
START!! 2022_09_30 / 18_10
model: bi
path: bert-base-uncased
trainset: persona_train_131438
validset: persona_valid_7801
m: 0
seed: 42
epoch: 5
learning rate: 5e-05
batch size: 256
accumulation: 1
language: en
description: 

train: 131438
valid: 7801
["Hi, how are you doing? I'm getting ready to do some cheetah chasing to stay in shape.", 'I am! For my hobby I like to do canning or some whittling.', "That's neat. When I was in high school I placed 6th in 100m dash!", 'I do not. But I do have a favorite meat since that is all I eat exclusively.', 'I would have to say its prime rib. Do you have any favorite foods?']
['You must be very fast. Hunting is one of my favorite hobbies.', 'I also remodel homes when I am not out bow hunting.', "That's awesome. Do you have a favorite season or time of year?", 'What is your favorite meat to eat?', 'I like chicken or macaroni and cheese.']

train loss: 9.486020284540514 / valid loss: 4.818001794815063 -------------------- epoch: 0 iteration: 51 ==> save
train loss: 5.311872865639481 / valid loss: 4.531008656819662 -------------------- epoch: 0 iteration: 102 ==> save
train loss: 4.9494062872493965 / valid loss: 4.412154626846314 -------------------- epoch: 0 iteration: 153 ==> save
train loss: 4.777531820185044 / valid loss: 4.327002223332723 -------------------- epoch: 0 iteration: 204 ==> save
train loss: 4.689981890659706 / valid loss: 4.27458758354187 -------------------- epoch: 0 iteration: 255 ==> save
scheduler!
train loss: 4.6173342816969924 / valid loss: 4.226537299156189 -------------------- epoch: 0 iteration: 306 ==> save
train loss: 4.528399336571787 / valid loss: 4.1939419110616045 -------------------- epoch: 0 iteration: 357 ==> save
train loss: 4.481717044231939 / valid loss: 4.184609651565552 -------------------- epoch: 0 iteration: 408 ==> save
train loss: 4.439494647231757 / valid loss: 4.135235293706258 -------------------- epoch: 0 iteration: 459 ==> save
train loss: 4.389491343030743 / valid loss: 4.1197828849156695 -------------------- epoch: 0 iteration: 510 ==> save
scheduler!
train loss: 4.53555154800415 / valid loss: 4.1203549861907955 -------------------- epoch: 1 iteration: 51
train loss: 4.207476550457525 / valid loss: 4.091775894165039 -------------------- epoch: 1 iteration: 102 ==> save
train loss: 4.158500404918895 / valid loss: 4.133314887682597 -------------------- epoch: 1 iteration: 153
train loss: 4.17718794299107 / valid loss: 4.066318058967591 -------------------- epoch: 1 iteration: 204 ==> save
train loss: 4.1773168526443785 / valid loss: 4.041881728172302 -------------------- epoch: 1 iteration: 255 ==> save
scheduler!
train loss: 4.157460240756764 / valid loss: 4.0411456028620405 -------------------- epoch: 1 iteration: 306 ==> save
train loss: 4.126886101330028 / valid loss: 4.025090964635213 -------------------- epoch: 1 iteration: 357 ==> save
train loss: 4.092663736904369 / valid loss: 4.045006990432739 -------------------- epoch: 1 iteration: 408
train loss: 4.096300578584858 / valid loss: 4.027211872736613 -------------------- epoch: 1 iteration: 459
train loss: 4.0702064037323 / valid loss: 4.005912192662557 -------------------- epoch: 1 iteration: 510 ==> save
scheduler!
train loss: 4.094546402201933 / valid loss: 4.038925894101461 -------------------- epoch: 2 iteration: 51
train loss: 3.841811049218271 / valid loss: 4.034587478637695 -------------------- epoch: 2 iteration: 102
train loss: 3.883363130045872 / valid loss: 4.04098953406016 -------------------- epoch: 2 iteration: 153
train loss: 3.8643573405695895 / valid loss: 3.995069885253906 -------------------- epoch: 2 iteration: 204 ==> save
train loss: 3.8465061234492883 / valid loss: 4.054656386375427 -------------------- epoch: 2 iteration: 255
scheduler!
train loss: 3.8223696876974667 / valid loss: 4.074087246259054 -------------------- epoch: 2 iteration: 306
train loss: 3.85402969753041 / valid loss: 4.021935232480367 -------------------- epoch: 2 iteration: 357
train loss: 3.833171372320138 / valid loss: 4.029639903704325 -------------------- epoch: 2 iteration: 408
train loss: 3.8453289340524113 / valid loss: 4.006939681371053 -------------------- epoch: 2 iteration: 459
train loss: 3.859933754977058 / valid loss: 3.97618137995402 -------------------- epoch: 2 iteration: 510 ==> save
scheduler!
train loss: 3.7731907835193708 / valid loss: 4.041379539171855 -------------------- epoch: 3 iteration: 51
train loss: 3.560957174675137 / valid loss: 4.025275985399882 -------------------- epoch: 3 iteration: 102
train loss: 3.5549719380397424 / valid loss: 4.076423756281534 -------------------- epoch: 3 iteration: 153
train loss: 3.575844746009976 / valid loss: 4.072244429588318 -------------------- epoch: 3 iteration: 204
train loss: 3.5627561270021926 / valid loss: 4.14244434038798 -------------------- epoch: 3 iteration: 255
scheduler!
train loss: 3.5856420526317523 / valid loss: 4.084020813306172 -------------------- epoch: 3 iteration: 306
train loss: 3.561868438533708 / valid loss: 4.061645634969076 -------------------- epoch: 3 iteration: 357
train loss: 3.5784874757130942 / valid loss: 4.057649087905884 -------------------- epoch: 3 iteration: 408
train loss: 3.589634717679491 / valid loss: 3.9974886576334634 -------------------- epoch: 3 iteration: 459
train loss: 3.571624283697091 / valid loss: 4.0735479911168415 -------------------- epoch: 3 iteration: 510
scheduler!
train loss: 3.3802852350122787 / valid loss: 4.160620800654093 -------------------- epoch: 4 iteration: 51
train loss: 3.2197250852397845 / valid loss: 4.263999851544698 -------------------- epoch: 4 iteration: 102
train loss: 3.2497693884606456 / valid loss: 4.158164620399475 -------------------- epoch: 4 iteration: 153
train loss: 3.2455417408662686 / valid loss: 4.093487429618835 -------------------- epoch: 4 iteration: 204
train loss: 3.3018842912187765 / valid loss: 4.213026563326518 -------------------- epoch: 4 iteration: 255
scheduler!
train loss: 3.2793124563553753 / valid loss: 4.087127820650736 -------------------- epoch: 4 iteration: 306
train loss: 3.294937526478487 / valid loss: 4.14563946723938 -------------------- epoch: 4 iteration: 357
train loss: 3.3168450757568957 / valid loss: 4.105264695485433 -------------------- epoch: 4 iteration: 408
train loss: 3.316311462252748 / valid loss: 4.120550680160522 -------------------- epoch: 4 iteration: 459
train loss: 3.33278946315541 / valid loss: 4.176835036277771 -------------------- epoch: 4 iteration: 510
scheduler!
END!! 2022_09_30 / 19_01
RUNNING TIME: 0:50:57
============================================================



SCORE!!
Namespace(best='0', device='cuda', lang='en', m=0, model='bi', path='bi220930_1810_bs256_ep5_data131438_en_best0', task='personachat', testset='persona_test_7512.pickle')
Load BiEncoder
bi220930_1810_bs256_ep5_data131438_en_best0
R@1/20: 50.31
MRR: 64.03
============================================================

SCORE!!
Namespace(best='1', device='cuda', lang='en', m=0, model='bi', path='bi220930_1810_bs256_ep5_data131438_en_best1', task='personachat', testset='persona_test_7512.pickle')
Load BiEncoder
bi220930_1810_bs256_ep5_data131438_en_best1
R@1/20: 50.57
MRR: 64.47
============================================================

