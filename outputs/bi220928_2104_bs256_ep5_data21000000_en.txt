============================================================
File Name: bi220928_2104_bs256_ep5_data21000000_en
START!! 2022_09_28 / 21_04
model: bi
path: bert-base-uncased
trainset: ubuntu2_train_1000000
validset: ubuntu2_valid_19560
m: 0
seed: 42
epoch: 5
learning rate: 5e-05
batch size: 256
accumulation: 1
language: en
description: 

train: 1000000
valid: 19560
["i think we could import the old comments via rsync, but from there we need to go via email. I think it is easier than caching the status on each bug and than import bits here and there __eou__ __eot__ it would be very easy to keep a hash db of message-ids  __eou__ sounds good __eou__ __eot__ ok __eou__ perhaps we can ship an ad-hoc apt_prefereces __eou__ __eot__ version? __eou__ __eot__ thanks __eou__ __eot__ not yet __eou__ it is covered by your insurance? __eou__ __eot__ yes __eou__ but it's really not the right time :/ __eou__ with a changing house upcoming in 3 weeks __eou__ __eot__ you will be moving into your house soon? __eou__ posted a message recently which explains what to do if the autoconfiguration does not do what you expect __eou__ __eot__ how urgent is #896? __eou__ __eot__ not particularly urgent, but a policy violation __eou__ __eot__ i agree that we should kill the -novtswitch __eou__ __eot__ ok __eou__ __eot__ would you consider a package split a feature? __eou__ __eot__ context? __eou__ __eot__ splitting xfonts* out of xfree86*. one upload for the rest of the life and that's it __eou__ __eot__ splitting the source package you mean? __eou__ __eot__ yes. same binary packages. __eou__ __eot__ I would prefer to avoid it at this stage.  this is something that has gone into XSF svn, I assume? __eou__ __eot__ ", 'I\'m not suggesting all - only the ones you modify. __eou__ __eot__ ok, it sounds like you\'re agreeing with me, then __eou__ though rather than "the ones we modify", my idea is "the ones we need to merge" __eou__ __eot__ ', "afternoon all __eou__ not entirely related to warty, but if grub-install takes 5 minutes to install, is this a sign that i should just retry the install :) __eou__ __eot__ here  __eou__ __eot__ you might want to know that thinice in warty is buggy compared to that in sid __eou__ __eot__ and apparently GNOME is suddently almost perfect (out of the thinice problem), nobody report bugs :-P __eou__ I don't get your question, where do you want to paste ? __eou__ __eot__ can i file the panel not linking to eds? :) __eou__ __eot__ are you using alt ? or the windows key ? __eou__ wait for the gnome-themes, component will be added __eou__ __eot__ i just restarted X and now nautilus won't show the desktop :( __eou__ hal isn't starting :( __eou__ __eot__ do you think we have any interest to have hal support turned on in gnome-vfs at this point ? It increases the sources of problems for no real benefit imho ... __eou__ __eot__ is it a known bug that g-s-t doesn't know what distribution its running on? __eou__ are there any changes to desktop-file-utils you've got hidden away? __eou__ __eot__ somebody should really kick that guy *hard* __eou__ I've added a build-dep on libxt-dev in warty for zenity __eou__ __eot__ arse. xt-dev? i added libx11-dev __eou__ so just libxt-dev or libxt and libx11? __eou__ for future note, the xmodmap line in that X sticky-super fixes the problem for me __eou__ __eot__ we have planned to speak about menu organisation during the 2 weeks __eou__ I need we don't need to force it __eou__ ? __eou__ __eot__ was away, you said ? __eou__ nope __eou__ __eot__ the warty repository __eou__ ok, fine. Thanks __eou__ nice to get packages update every 30min instead once a day, isn't it :) __eou__ __eot__ you'll be glad to know i've fixed my missing arrows in thinice bug __eou__ __eot__ I've uploaded the gnome-vfs without hal support should be available rsn __eou__ __eot__ should g2 in ubuntu do the magic dont-focus-window tricks? __eou__ join the gang, get an x-series thinkpad __eou__ sj has hung on my box, again. __eou__ what is monday mornings discussion actually about? __eou__ __eot__ ", "interesting __eou__ grub-install worked with / being ext3, failed when it was xfs __eou__ i thought d-i installed the relevant kernel for your machine. i have a p4 and its installed the 386 kernel __eou__ holy crap a lot of stuff gets installed by default :) __eou__ YOU ARE INSTALLING VIM ON A BOX OF MINE __eou__ ;) __eou__ __eot__ more like osx than debian ;) __eou__ we have a selection of python modules available for great justice (and python development) __eou__ __eot__ 2.8 is fixing them iirc __eou__ __eot__ pong __eou__ vino will be in __eou__ enjoying ubuntu? __eou__ __eot__ told me to come here __eou__ suggested thursday as a good day to come __eou__ __eot__ we froze versions a while back :) __eou__ you coming today or thursday? __eou__ we're considering shifting it __eou__ yay __eou__ enjoying ubuntu? __eou__ usplash! __eou__ __eot__ thats the one __eou__ __eot__ so i saw your email with the mockup at the airport, but it hasn't appeared now that i've pulled my mail :| __eou__ __eot__ i've got a better one now too, give me a minute __eou__ we've got rh9 installed on most desktops. you want me to look at up2date, right? __eou__ __eot__ aha! no, the gui thingy __eou__ it's more wizardy __eou__ so the first page is okayish __eou__ we can do a whole load better on the second page (icons, translated descriptions) __eou__ but that's the kind of thing i was thinking about __eou__ (a single big treeview would get very scary, very quickly) __eou__ sure it's not a hurricane? __eou__ __eot__ i think experimental is getting 2.8 too __eou__ let him work on #1217 :) __eou__ __eot__ we call it 'universe' ;) __eou__ haha __eou__ ooh, totally __eou__ __eot__ i want it on in sarge too but nobody else agrees __eou__ __eot__ ", 'and because Python gives Mark a woody __eou__ __eot__ i\'m not sure if we\'re meant to talk about that publically yet. __eou__ __eot__ and I thought we were a "pants off" kind of company ... :p __eou__ you need new glasses __eou__ __eot__ mono 1.0? dude, that\'s going to be a barrel of laughs for totally non-release related reasons during hoary __eou__ read bryan clark\'s entry about NetworkManager? __eou__ __eot__ there was an accompanying IRC conversation to that one <g> __eou__ explain ? __eou__ I guess you could ship the new png in the debian/ directory and copy them over in your rules __eou__ __eot__ but debian/ is also part of diff.gz... __eou__ you can fix this for the common people, dude! multiple tarballs in source! __eou__ __eot__ NOTWARTY, HTH, HAND, KTHXBYE <g> __eou__ everyone else had their macs stolen, so can\'t really comment __eou__ that picture of you is a classic __eou__ __eot__ which? __eou__ the best feature of the new imac is that the old imacs are going to be cheaper! __eou__ ooh, can you add that to the wiki? __eou__ __eot__ k. __eou__ you getting two-weeks-to-release edginess? __eou__ http://descent.netsplit.com/~scott/kids.mp3 -- but for releases __eou__ I played with an x300 about the time I bought my new laptop, it didn\'t feel solid at all __eou__ __eot__ which series is yours again? __eou__ nc8000? __eou__ mmm __eou__ __eot__ you have my sympathy __eou__ I\'m trying to *find* the definition I wrote __eou__ __eot__ it\'d be on Glossary __eou__ i know i wrote one there __eou__ __eot__ I\'m trying to find the one with mdz\'s l33t dot madness __eou__ that would be a pretty good look for you :p __eou__ bandwidth bills? __eou__ __eot__ i\'m reverting the wifi change; i don\'t think the bars are the right thing, but they\'re better than the current one. __eou__ ooh, that\'d be rad __eou__ __eot__ not about waiting?  clearly you haven\'t tried to read a site that\'s just made slashdot? __eou__ __eot__ ']
['basically each xfree86 upload will NOT force users to upgrade 100Mb of fonts for nothing __eou__ no something i did in my spare time. __eou__', 'oh? oops. __eou__', "we'll have a BOF about this __eou__ so you're coming tomorrow ? __eou__", 'i fully endorse this suggestion </quimby> __eou__ how did your reinstall go? __eou__', "(i thought someone was going to make a joke about .au bandwidth...) __eou__ especially not if you're using screen ;) __eou__"]

train loss: 5.099946760519957 / valid loss: 4.462677811321459 -------------------- epoch: 0 iteration: 390 ==> save
train loss: 4.550355284030621 / valid loss: 4.324999068912707 -------------------- epoch: 0 iteration: 780 ==> save
train loss: 4.403312750351735 / valid loss: 4.204724314965699 -------------------- epoch: 0 iteration: 1170 ==> save
train loss: 4.302081499344263 / valid loss: 4.123327499941776 -------------------- epoch: 0 iteration: 1560 ==> save
scheduler!
train loss: 4.251609643300374 / valid loss: 4.117431116731543 -------------------- epoch: 0 iteration: 1950 ==> save
train loss: 4.191677986047207 / valid loss: 4.031406214362697 -------------------- epoch: 0 iteration: 2340 ==> save
train loss: 4.1440367068999855 / valid loss: 4.035042339249661 -------------------- epoch: 0 iteration: 2730
train loss: 4.112306589957996 / valid loss: 4.012378212652709 -------------------- epoch: 0 iteration: 3120 ==> save
train loss: 4.066947589776455 / valid loss: 3.962142395345788 -------------------- epoch: 0 iteration: 3510 ==> save
scheduler!
train loss: 4.05609913667043 / valid loss: 3.980587971837897 -------------------- epoch: 0 iteration: 3900
train loss: 3.958877916825123 / valid loss: 3.939727450671949 -------------------- epoch: 1 iteration: 390 ==> save
train loss: 3.873371533247141 / valid loss: 3.9103267788887024 -------------------- epoch: 1 iteration: 780 ==> save
train loss: 3.8711735658156567 / valid loss: 3.914127992956262 -------------------- epoch: 1 iteration: 1170
train loss: 3.8556639799704917 / valid loss: 3.912873914367274 -------------------- epoch: 1 iteration: 1560
scheduler!
train loss: 3.849285325025901 / valid loss: 3.9018693440838863 -------------------- epoch: 1 iteration: 1950 ==> save
train loss: 3.8354705107517733 / valid loss: 3.8743393421173096 -------------------- epoch: 1 iteration: 2340 ==> save
train loss: 3.817492461204529 / valid loss: 3.8479411947099784 -------------------- epoch: 1 iteration: 2730 ==> save
train loss: 3.8021733357356147 / valid loss: 3.8437485820368718 -------------------- epoch: 1 iteration: 3120 ==> save
train loss: 3.7997029188351754 / valid loss: 3.891614562586734 -------------------- epoch: 1 iteration: 3510
scheduler!
train loss: 3.8092022920266175 / valid loss: 3.831223337273849 -------------------- epoch: 1 iteration: 3900 ==> save
train loss: 3.627790234027765 / valid loss: 3.8495191743499353 -------------------- epoch: 2 iteration: 390
train loss: 3.570919332137475 / valid loss: 3.8279967590382227 -------------------- epoch: 2 iteration: 780 ==> save
train loss: 3.583614836594997 / valid loss: 3.838064570175974 -------------------- epoch: 2 iteration: 1170
train loss: 3.5813560516406326 / valid loss: 3.8269160389900208 -------------------- epoch: 2 iteration: 1560 ==> save
scheduler!
train loss: 3.5909224614118918 / valid loss: 3.821454653614446 -------------------- epoch: 2 iteration: 1950 ==> save
train loss: 3.581950985468351 / valid loss: 3.8352148815205225 -------------------- epoch: 2 iteration: 2340
train loss: 3.5829036095203497 / valid loss: 3.8204855793400814 -------------------- epoch: 2 iteration: 2730 ==> save
train loss: 3.574402148907001 / valid loss: 3.8219593669238843 -------------------- epoch: 2 iteration: 3120
train loss: 3.57660622046544 / valid loss: 3.8060090792806527 -------------------- epoch: 2 iteration: 3510 ==> save
scheduler!
train loss: 3.568445743047274 / valid loss: 3.7689303222455477 -------------------- epoch: 2 iteration: 3900 ==> save
train loss: 3.3650634398827184 / valid loss: 3.874133803342518 -------------------- epoch: 3 iteration: 390
train loss: 3.3128687644616153 / valid loss: 3.912500980653261 -------------------- epoch: 3 iteration: 780
train loss: 3.337847289060935 / valid loss: 3.897678886589251 -------------------- epoch: 3 iteration: 1170
train loss: 3.328013218366183 / valid loss: 3.846846960092846 -------------------- epoch: 3 iteration: 1560
scheduler!
train loss: 3.344842334282704 / valid loss: 3.888540948692121 -------------------- epoch: 3 iteration: 1950
train loss: 3.355953189042898 / valid loss: 3.8506628619997123 -------------------- epoch: 3 iteration: 2340
train loss: 3.360362475957626 / valid loss: 3.8289501102347123 -------------------- epoch: 3 iteration: 2730
train loss: 3.357126504335648 / valid loss: 3.8360639936045597 -------------------- epoch: 3 iteration: 3120
train loss: 3.3613523642222085 / valid loss: 3.815883862344842 -------------------- epoch: 3 iteration: 3510
scheduler!
train loss: 3.365118881983635 / valid loss: 3.8485951455015885 -------------------- epoch: 3 iteration: 3900
train loss: 3.101308607443785 / valid loss: 3.910010692320372 -------------------- epoch: 4 iteration: 390
train loss: 3.0765364524645684 / valid loss: 3.963427854211707 -------------------- epoch: 4 iteration: 780
train loss: 3.0905884651037363 / valid loss: 3.8916740197884407 -------------------- epoch: 4 iteration: 1170
train loss: 3.115330609297141 / valid loss: 3.9081349341492904 -------------------- epoch: 4 iteration: 1560
scheduler!
train loss: 3.1216804320995624 / valid loss: 3.888881909219842 -------------------- epoch: 4 iteration: 1950
train loss: 3.1298064005680573 / valid loss: 3.919128113671353 -------------------- epoch: 4 iteration: 2340
train loss: 3.1201718898919912 / valid loss: 3.8828712952764413 -------------------- epoch: 4 iteration: 2730
train loss: 3.142893865169623 / valid loss: 3.8643851499808464 -------------------- epoch: 4 iteration: 3120
train loss: 3.134695017643464 / valid loss: 3.9245249597649825 -------------------- epoch: 4 iteration: 3510
scheduler!
train loss: 3.1504401011344716 / valid loss: 3.869630870066191 -------------------- epoch: 4 iteration: 3900
END!! 2022_09_29 / 04_18
RUNNING TIME: 7:14:09
============================================================



SCORE!!
Namespace(best='0', device='cuda', lang='en', m=0, model='bi', path='bi220928_2104_bs256_ep5_data21000000_en_best0', task='ubuntu2', testset='ubuntu2_test_18920.pickle')
Load BiEncoder
bi220928_2104_bs256_ep5_data21000000_en_best0
R@1/10: 59.7
MRR: 72.6
============================================================

SCORE!!
Namespace(best='1', device='cuda', lang='en', m=0, model='bi', path='bi220928_2104_bs256_ep5_data21000000_en_best1', task='ubuntu2', testset='ubuntu2_test_18920.pickle')
Load BiEncoder
bi220928_2104_bs256_ep5_data21000000_en_best1
R@1/10: 60.26
MRR: 73.05
============================================================

